{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smart-motorcycle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T06:19:08.234171Z",
     "iopub.status.busy": "2021-03-06T06:19:08.233175Z",
     "iopub.status.idle": "2021-03-06T06:19:09.707351Z",
     "shell.execute_reply": "2021-03-06T06:19:09.707351Z",
     "shell.execute_reply.started": "2021-03-06T06:19:08.233175Z"
    }
   },
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import requests \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "# psycopg2 works in tandem with sqlalchemy \n",
    "import psycopg2\n",
    "# import custom module with database parameters \n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "horizontal-scratch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T06:19:11.120151Z",
     "iopub.status.busy": "2021-03-06T06:19:11.120151Z",
     "iopub.status.idle": "2021-03-06T06:19:11.160051Z",
     "shell.execute_reply": "2021-03-06T06:19:11.159047Z",
     "shell.execute_reply.started": "2021-03-06T06:19:11.120151Z"
    }
   },
   "outputs": [],
   "source": [
    "# etl pipelien function \n",
    "#--extraction---\n",
    "def extract_transform_load(api_endpoint, new_databse_name, api_parameters=None):\n",
    "    \n",
    "    data_request = requests.get(url=api_endpoint, params=api_parameters)\n",
    "    \n",
    "    data_df = pd.DataFrame.from_records(data_request.json())\n",
    "    \n",
    "    report_df = pd.DataFrame({'Rows Retrieved':{0:len(data_df)}})\n",
    "    \n",
    "    \n",
    " #--cleaning--\n",
    "    #drop columns \n",
    "    drop_columns = ['location', 'x_coordinate', 'y_coordinate',\n",
    "                    'occ_date', 'occ_time','rep_date','rep_time','category_description', 'address',\n",
    "                    'ucr_category','census_tract','sector','pra','council_district']\n",
    "    \n",
    "    data_df.drop(drop_columns, axis=1, inplace=True)\n",
    "    \n",
    "    #drop null values \n",
    "    # drop rows with missing data\n",
    "    column_checklist = ['incident_report_number', 'crime_type', 'ucr_code', 'family_violence',\n",
    "                       'occ_date_time', 'rep_date_time', 'location_type', 'zip_code',\n",
    "                         'latitude', 'longitude','district']\n",
    "    # track how many row with missing data is being dropped \n",
    "    row_counter = 0\n",
    "    for i in column_checklist:\n",
    "        if data_df[i].isnull().sum() > 0:\n",
    "            row_counter += data_df[i].isnull().sum()\n",
    "            data_df.drop(data_df[data_df[i].isnull()].index, inplace=True)\n",
    "    \n",
    "    report_df['Rows Dropped'] = row_counter\n",
    "                 \n",
    "    #fill in clearance data with placeholders \n",
    "    #data_df['clearance_date'].fillna(value='0000-00-00T00:00:00.000',inplace=True)\n",
    "    data_df['clearance_status'].fillna(value='N', inplace=True)\n",
    "        \n",
    "    #clean and convert datetiem columns \n",
    "    data_df['occ_date_time'] = data_df['occ_date_time'].apply(lambda x: x.replace('T',' '))\n",
    "    data_df['rep_date_time'] = data_df['rep_date_time'].apply(lambda x: x.replace('T',' '))\n",
    "    \n",
    "    #rename columns \n",
    "    column_names = {'ucr_code':'offense_code','occ_date_time':'occurred_date',\n",
    "                    'rep_date_time':'reported_date','crime_type':'offense_type'}\n",
    "    \n",
    "    data_df.rename(columns=column_names, inplace=True)\n",
    "    \n",
    "    print(report_df)\n",
    "    print('\\n')\n",
    "    \n",
    "   \n",
    " #--transform--\n",
    "    #offense_type_table \n",
    "    offense_df = data_df[['offense_code','offense_type']].copy()\n",
    "    offense_df.drop_duplicates(subset='offense_code',inplace=True)\n",
    "    \n",
    "    #create incident_location_table \n",
    "    # double brackets needed to create series, works like \"to_frame\" but is inplace \n",
    "    location_df = data_df[['location_type']].copy()\n",
    "    location_df.drop_duplicates(inplace=True)\n",
    "    location_df['location_code'] = np.arange(len(location_df))\n",
    "    \n",
    "    #create mapping for location_code column\n",
    "    location_map_df = location_df.copy(deep=True)\n",
    "    location_map_df.set_index('location_type', inplace=True) \n",
    "    location_mapper = location_map_df.to_dict()['location_code']\n",
    "        \n",
    "    # rearrange location_df\n",
    "    location_df = location_df[['location_code','location_type']]\n",
    "    \n",
    "    #crime_incidents_table \n",
    "    #create encoded location_code column\n",
    "    crime_incident_df = data_df.copy()\n",
    "    crime_incident_df['location_code'] = crime_incident_df['location_type'] \\\n",
    "        .apply(lambda x: location_mapper[x])\n",
    "    \n",
    "    #drop repetitive offense and location columns \n",
    "    drop_column_2 = ['offense_type','location_type']\n",
    "    crime_incident_df.drop(drop_column_2,axis=1, inplace=True)\n",
    "    \n",
    "#--load--\n",
    "    #connect to default database with psycopg2 library \n",
    "    #query to create database for data \n",
    "    #transactions that create databases have to be fully commited and closed \n",
    "    conn = psycopg2.connect(database=\"postgres\", user=config.db_user, password=config.db_password)\n",
    "    cur = conn.cursor()\n",
    "    conn.autocommit = True\n",
    "    cur.execute(''f'CREATE DATABASE {new_databse_name};''')\n",
    "    conn.close()\n",
    "    \n",
    "    # create new transaction to create database tables \n",
    "    conn = psycopg2.connect(database=f\"{new_databse_name}\", user=config.db_user, password=config.db_password)\n",
    "    cur = conn.cursor()\n",
    "    # query to create tables \n",
    "    cur.execute('''\n",
    "        \n",
    "            CREATE TABLE crime_incidents (\n",
    "                incident_report_number BIGINT PRIMARY KEY, \n",
    "                offense_code TEXT,\n",
    "                family_violence BOOLEAN,\n",
    "                occurred_date TIMESTAMP,\n",
    "                reported_date TIMESTAMP,\n",
    "                zip_code TEXT,\n",
    "                district TEXT,\n",
    "                latitude DOUBLE PRECISION,\n",
    "                longitude DOUBLE PRECISION,\n",
    "                clearance_status TEXT,\n",
    "                clearance_date DATE,\n",
    "                location_code TEXT );\n",
    "            CREATE TABLE incident_location (\n",
    "                location_code TEXT PRIMARY KEY,\n",
    "                location_type TEXT );\n",
    "            CREATE TABLE offense_type (\n",
    "                offense_code TEXT PRIMARY KEY,\n",
    "                offense_type TEXT\n",
    "            );''')\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    #setup sqlalchemy database connection \n",
    "    database = f\"postgres://{config.db_user}:{config.db_password}@localhost:5432/{new_databse_name}\"\n",
    "    engine = create_engine(database)   \n",
    "    \n",
    "    #load crime table \n",
    "    print('loading crime_incident table')\n",
    "    start_time = time.time()\n",
    "    crime_incident_df.to_sql(name='crime_incidents',index=False, con=engine, if_exists='append', chunksize=100000)\n",
    "    print(f'{time.time() - start_time} seconds to load crime table \\n')                                    \n",
    "    \n",
    "    #load location table \n",
    "    print('loading incident_location table \\n')\n",
    "    location_df.to_sql(name='incident_location', index=False, con=engine, if_exists='append')\n",
    "    \n",
    "    #load offense table \n",
    "    print('loading offense_type table')\n",
    "    offense_df.to_sql(name='offense_type', index=False, con=engine, if_exists='append')\n",
    "    \n",
    "    \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-luxembourg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T06:19:16.718924Z",
     "iopub.status.busy": "2021-03-06T06:19:16.717927Z",
     "iopub.status.idle": "2021-03-06T06:19:16.723914Z",
     "shell.execute_reply": "2021-03-06T06:19:16.722914Z",
     "shell.execute_reply.started": "2021-03-06T06:19:16.718924Z"
    }
   },
   "outputs": [],
   "source": [
    "# api endpoint with custom date filter for data beween 2018 - 2020\n",
    "# limit is set to be higher than data rows being retrieved \n",
    "url = \"https://data.austintexas.gov/resource/fdj4-gpfu.json?$limit=500000&$where=occ_date between '2018-01-01T00:00:00.000' and '2020-12-31T23:59:59.000'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beautiful-treat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T06:20:39.179436Z",
     "iopub.status.busy": "2021-03-06T06:20:39.178439Z",
     "iopub.status.idle": "2021-03-06T06:22:54.414449Z",
     "shell.execute_reply": "2021-03-06T06:22:54.413450Z",
     "shell.execute_reply.started": "2021-03-06T06:20:39.179436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rows Retrieved  Rows Dropped\n",
      "0          310981          7042\n",
      "\n",
      "\n",
      "loading crime_incident table\n",
      "71.18055248260498 seconds to load crime table \n",
      "\n",
      "loading incident_location table \n",
      "\n",
      "loading offense_type table\n"
     ]
    }
   ],
   "source": [
    "extract_transform_load(api_endpoint=url, new_databse_name='austin_crime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-anchor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
